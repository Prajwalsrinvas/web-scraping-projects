{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many pages do you want to scrape\n",
      "Enter all if you want to scrape all pages:\n",
      "all\n",
      "Page 1 scraped\n",
      "Page 2 scraped\n",
      "Page 3 scraped\n",
      "Page 4 scraped\n",
      "Page 5 scraped\n",
      "Page 6 scraped\n",
      "Page 7 scraped\n",
      "Page 8 scraped\n",
      "Page 9 scraped\n",
      "Page 10 scraped\n",
      "Page 11 scraped\n",
      "Page 12 scraped\n",
      "Page 13 scraped\n",
      "Page 14 scraped\n",
      "Page 15 scraped\n",
      "Page 16 scraped\n",
      "Page 17 scraped\n",
      "Page 18 scraped\n",
      "Page 19 scraped\n",
      "Page 20 scraped\n",
      "Page 21 scraped\n",
      "Page 22 scraped\n",
      "Page 23 scraped\n",
      "Page 24 scraped\n",
      "Page 25 scraped\n",
      "Page 26 scraped\n",
      "Page 27 scraped\n",
      "Page 28 scraped\n",
      "Page 29 scraped\n",
      "Page 30 scraped\n",
      "Page 31 scraped\n",
      "Page 32 scraped\n",
      "Page 33 scraped\n",
      "Page 34 scraped\n",
      "Page 35 scraped\n",
      "Page 36 scraped\n",
      "Page 37 scraped\n",
      "Page 38 scraped\n",
      "Page 39 scraped\n",
      "Page 40 scraped\n",
      "Page 41 scraped\n",
      "All Pages scraped and car data is stored in csv file!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "first_page_url = 'https://www.carpages.ca/used-cars/search/?fueltype_id%5B0%5D=3&fueltype_id%5B1%5D=7'\n",
    "df = pd.DataFrame(columns=['Car name', 'Description','Mileage', 'Price', 'Colour', 'Link'])\n",
    "page_count = 1\n",
    "\n",
    "# scrapes all car info in a page in the given url\n",
    "def car_info(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, parser='lxml')\n",
    "    cars = soup.find_all('div', class_='l-column l-column--large-8')\n",
    "    global page_count,max_pages\n",
    "\n",
    "    for car in cars:\n",
    "        try:\n",
    "            car_name = car.find('a').text.strip()\n",
    "            desc = car.find('h5').text.strip()\n",
    "            mileage = car.find('div', class_='grey l-column l-column--small-6 l-column--medium-4').text.strip()\n",
    "            price = car.find('strong', class_='delta').text.strip()\n",
    "            colour = car.find_all('div', class_='grey l-column l-column--small-6 l-column--medium-4')[1].text.strip()\n",
    "            link = 'https://www.carpages.ca' + car.find('a').get('href')\n",
    "            index = len(df)\n",
    "            df.loc[index] = [car_name, desc, mileage, price, colour, link]\n",
    "        except:\n",
    "            pass\n",
    "     \n",
    "    # if user has given the number of pages to be scraped and next page is available\n",
    "    if max_pages != 'all' and soup.find_all('a', class_='nextprev')[-1].text == 'Next »':\n",
    "        next_page_url = soup.find_all('a', class_='nextprev')[-1].get('href')\n",
    "        print(f\"Page {page_count} scraped\")\n",
    "        if page_count < int(max_pages):\n",
    "            page_count += 1\n",
    "            car_info(next_page_url)\n",
    "        else:\n",
    "            df.to_csv('car_data.csv',index=False)\n",
    "            print(f'{page_count} Pages scraped and car data is stored in csv file!')\n",
    "            exit()\n",
    "            \n",
    "    # if user wants to scrape all pages and next page is available\n",
    "    elif soup.find_all('a', class_='nextprev')[-1].text == 'Next »':\n",
    "        next_page_url = soup.find_all('a', class_='nextprev')[-1].get('href')\n",
    "        print(f\"Page {page_count} scraped\")\n",
    "        page_count += 1\n",
    "        car_info(next_page_url)\n",
    "\n",
    "    else:\n",
    "        df.to_csv('car_data.csv',index=False)\n",
    "        print('All Pages scraped and car data is stored in csv file!')\n",
    "        exit()\n",
    "        \n",
    "max_pages = input(\"How many pages do you want to scrape\\nEnter all if you want to scrape all pages:\\n\")\n",
    "if max_pages == 'all':\n",
    "    car_info(first_page_url)\n",
    "else:\n",
    "    car_info(first_page_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
